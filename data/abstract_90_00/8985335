Treatment of human immunodeficiency virus type 1 (HIV-1) infection during the clinical latency phase with drugs inhibiting reverse transcriptase (RT) reduces the HIV-1 RNA load and increases the CD4+ T-cell count. Typically, however, the virus evolves mutations in the RT gene that circumvent the drugs. We develop a mathematical model for this situation. The model distinguishes quiescent from activated CD4+ T cells, incorporates the fact that only activated cells can become productively infected by HIV-1, embodies empirical estimates for the drug resistance and the mutation frequency for each of the HIV-1 drug-resistant mutants, and assumes the antiviral immune response to remain constant over the course of the experiments. We analyze clinical data on the evolution of drug-resistant mutants for the RT inhibitors lamivudine and zidovudine. The results show that the evolutionary sequence of the drug-resistant mutants in both data sets is accounted for by our model, given that lamivudine is more effective than zidovudine. Thus, current empirical estimates of the mutation frequencies and the drug resistances of the mutants suffice for explaining the data. We derive a critical treatment level below which the wild-type HIV-1 RNA load can rebound before the first drug-resistant mutant appears. Our zidovudine data confirm this to be the case. Thus, we demonstrate in the model and the data that the rebound of the HIV-1 RNA load in the case of zidovudine is due to the outgrowth of wild-type virus and the first drug-resistant mutant, whereas that in the case of lamivudine can only be due to the drug-resistant mutants. The evolution of drug resistance proceeds slower in the case of zidovudine because (i) zidovudine is not as effective as lamivudine and (ii) the first zidovudine drug-resistant mutant is competing with the rebounding wild-type virus.