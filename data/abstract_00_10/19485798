Malaria, a leading parasitic disease, inflicts an enormous toll on human lives and is caused by protozoal parasites belonging to the genus Plasmodium. Antimalarial drugs targeting essential biochemical processes in the parasite are the primary resources for management and control. However, the parasite has established mutations, substantially reducing the efficacy of these drugs. First-line therapy is faced the with the consistent evolution of drug-resistant genotypes carrying these mutations. However, drug-resistant genotypes are likely to be less fit than the wild-type, suggesting that they might disappear by reducing the volume of drug pressure. A substantial body of epidemiological evidence confirmed that the frequency of resistant genotypes wanes when active drug selection declines. Drug selection on the parasite genome that removes genetic variation in the vicinity of drug-resistant genes (hitch-hiking) is common among resistant parasites in the field. This can further disadvantage drug-resistant strains and limit their variability in the face of a mounting immune response. Attempts to provide unequivocal evidence for the fitness cost of drug resistance have monitored the outcomes of laboratory competition experiments of deliberate mixtures of sensitive and resistant strains, in the absence of drug pressure, using isogenic clones produced either by drug selection or gene manipulation. Some of these experiments provided inconclusive results, but they all suggested reduced fitness of drug-resistant clones in the absence of drug pressure. In addition, biochemical analyses provided clearer information demonstrating that the mutation of some antimalarial-targeted enzymes lowers their activity compared with the wild-type enzyme. Here, we review current evidences for the disadvantage of drug-resistance mutations, and discuss some strategies of drug deployment to maximize the cost of resistance and limit its spread.