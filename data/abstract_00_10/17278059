The mutant selection window hypothesis postulates that, for each antimicrobial-pathogen combination, an antimicrobial concentration range exists in which selective amplification of single-step, drug-resistant mutants occurs. This hypothesis suggests an antimutant dosing strategy that is keyed to the upper boundary of the selection window: the mutant prevention concentration. Correlations are described between the mutant prevention concentration--a static parameter that is measured with agar plates--and fluctuating drug concentrations that restrict mutant amplification in vitro and in animals. When drug resistance is acquired stepwise, the mutant selection window increases, making the suppression of each successive mutant increasingly more difficult. For agents that kill drug-resistant mutants in a drug concentration-dependent manner, the use of the area under the 24-h time-drug concentration curve value divided by the value of the mutant prevention concentration is suggested as an index for designing antimutant dosing regimens. The need for such regimens is emphasized by a clinical example in which acquisition of drug resistance occurs concurrently with eradication of susceptible bacterial cells. These data support using the mutant selection window to optimize antimicrobial dosing regimens.