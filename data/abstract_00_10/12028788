This paper seeks to define and quantify the influence of drug elimination half-life on the evolution of antimalarial drug resistance. There are assumed to be three general classes of susceptibility of the malaria parasite Plasmodium falciparum to a drug: Res0, the original, susceptible wildtype; Res1, a group of intermediate levels of susceptibility that are more tolerant of the drug but still cleared by treatment; and Res2, which is completely resistant to the drug. Res1 and Res2 resistance both evolve much faster if the antimalarial drug has a long half-life. We show that previous models have significantly underestimated the rate of evolution of Res2 resistance by omitting the effects of drug half-life. The methodology has been extended to investigate (i) the effects of using drugs in combination, particularly when the components have differing half-lives, and (ii) the specific example of the development of resistance to the antimalarial pyrimethamine-sulphadoxine. An important detail of the model is the development of drug resistance in two separate phases. In phase A, Res1 is spreading and replacing the original sensitive forms while Res2 remains at a low level. Phase B starts once parasites are selected that can escape drug action (Res1 genotypes with borderline chemosensitivity, and Res2): these parasites are rapidly selected, a process that leads to widespread clinical failure. Drug treatment is clinically successful during phase A, and health workers may be unaware of the substantial changes in parasite population genetic structure that predicate the onset of phase B. Surveillance programs are essential, following the introduction of a new drug, to monitor effectively changes in treatment efficacy and thus provide advance warning of drug failure. The model is also applicable to the evolution of antibiotic resistance in bacteria: in particular, the need for these models to incorporate drug pharmacokinetics to avoid potentially large errors in their predictions.