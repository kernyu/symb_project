Antiretroviral-based microbicides may offer a means to reduce the sexual transmission of HIV-1. Suboptimal use of a microbicide may, however, lead to the development of drug resistance in users that are already, or become, infected with HIV-1. In such cases, the efficacy of treatments may be compromised since the same (or similar) antiretrovirals used in treatments are being developed as microbicides. To help predict which drug resistance mutations may develop in the context of suboptimal use, HIV-1 primary isolates of different subtypes and different baseline resistance profiles were used to infect primary cells in vitro in the presence of increasing suboptimal concentrations of the two candidate microbicide antiretrovirals dapivirine (DAP) and tenofovir (TFV) alone or in combination. Infections were ongoing for 25 weeks, after which reverse transcriptase genotypes were determined and scrutinized for the presence of any clinically recognized reverse transcriptase drug resistance mutations. Results indicated that suboptimal concentrations of DAP alone facilitated the emergence of common nonnucleoside reverse transcriptase inhibitor resistance mutations, while suboptimal concentrations of DAP plus TFV gave rise to fewer mutations. Suboptimal concentrations of TFV alone did not frequently result in the development of resistance mutations. Sensitivity evaluations for stavudine (d4T), nevirapine (NVP), and lamivudine (3TC) revealed that the selection of resistance as a consequence of suboptimal concentrations of DAP may compromise the potential for NVP to be used in treatment, a finding of potential relevance in developing countries.