High-dose chemotherapy has long been advocated as a means of controlling drug resistance in infectious diseases but recent empirical studies have begun to challenge this view. We develop a very general framework for modeling and understanding resistance emergence based on principles from evolutionary biology. We use this framework to show how high-dose chemotherapy engenders opposing evolutionary processes involving the mutational input of resistant strains and their release from ecological competition. Whether such therapy provides the best approach for controlling resistance therefore depends on the relative strengths of these processes. These opposing processes typically lead to a unimodal relationship between drug pressure and resistance emergence. As a result, the optimal drug dose lies at either end of the therapeutic window of clinically acceptable concentrations. We illustrate our findings with a simple model that shows how a seemingly minor change in parameter values can alter the outcome from one where high-dose chemotherapy is optimal to one where using the smallest clinically effective dose is best. A review of the available empirical evidence provides broad support for these general conclusions. Our analysis opens up treatment options not currently considered as resistance management strategies, and it also simplifies the experiments required to determine the drug doses which best retard resistance emergence in patients.